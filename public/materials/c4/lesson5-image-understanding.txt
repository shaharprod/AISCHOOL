Image Understanding - ×”××“×¨×™×š ×”×©×œ×
====================================

×©×™×¢×•×¨ 5: Image Understanding
==============================

××” ×–×” Image Understanding?
===========================

Image Understanding ×”×™× ×”×™×›×•×œ×ª ×©×œ ×”××•×“×œ ×œ× ×ª×— ×•×œ×”×‘×™×Ÿ ×ª××•× ×•×ª:
â€¢ ×–×™×”×•×™ ××•×‘×™×™×§×˜×™×
â€¢ ×ª×™××•×¨ ×ª××•× ×•×ª
â€¢ ×©××œ×•×ª ×¢×œ ×ª××•× ×•×ª
â€¢ × ×™×ª×•×— ×•×™×–×•××œ×™

×œ××” ×–×” ×—×©×•×‘?
=============

â€¢ ×¢×‘×•×“×” ×¢× ×ª××•× ×•×ª
â€¢ × ×™×ª×•×— ×•×™×–×•××œ×™
â€¢ ×–×™×”×•×™ ×ª×•×›×Ÿ
â€¢ ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××‘×•×¡×¡ ×ª××•× ×•×ª

××™×š ×–×” ×¢×•×‘×“?
=============

1. ×”×¢×œ××ª ×ª××•× ×”
---------------

Python:
```python
import google.generativeai as genai
import PIL.Image

genai.configure(api_key="YOUR_API_KEY")

# ×˜×¢×™× ×ª ×ª××•× ×”
img = PIL.Image.open("image.jpg")

model = genai.GenerativeModel("gemini-1.5-pro-vision")
response = model.generate_content(["×ª××¨ ××ª ×”×ª××•× ×”", img])
print(response.text)
```

JavaScript:
```javascript
const { GoogleGenerativeAI } = require("@google/generative-ai");
const fs = require("fs");

const genAI = new GoogleGenerativeAI("YOUR_API_KEY");
const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro-vision" });

// ×§×¨×™××ª ×ª××•× ×”
const imageData = fs.readFileSync("image.jpg");
const imagePart = {
    inlineData: {
        data: imageData.toString("base64"),
        mimeType: "image/jpeg"
    }
};

const result = await model.generateContent([
    "×ª××¨ ××ª ×”×ª××•× ×”",
    imagePart
]);
console.log(result.response.text());
```

2. ×ª×™××•×¨ ×ª××•× ×” ×‘×¡×™×¡×™
---------------------

```python
def describe_image(image_path, language="hebrew"):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = f"×ª××¨ ××ª ×”×ª××•× ×” ×‘×¤×™×¨×•×˜ ×‘×¢×‘×¨×™×ª"
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
description = describe_image("photo.jpg")
print(description)
```

3. ×©××œ×•×ª ×¢×œ ×ª××•× ×”
-------------------

```python
def ask_about_image(image_path, question):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    response = model.generate_content([question, img])
    return response.text

# ×©×™××•×©
answer = ask_about_image("photo.jpg", "××” ×”×¦×‘×¢×™× ×”×¢×™×§×¨×™×™× ×‘×ª××•× ×”?")
print(answer)
```

×“×•×’×××•×ª ×©×™××•×©×™×•×ª
==================

×“×•×’××” 1: ×–×™×”×•×™ ××•×‘×™×™×§×˜×™×
---------------------------

```python
def identify_objects(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×–×”×” ××ª ×›×œ ×”××•×‘×™×™×§×˜×™× ×‘×ª××•× ×”.
×”×—×–×¨ ×¨×©×™××” ×©×œ ×›×œ ×”××•×‘×™×™×§×˜×™× ×¢× ××™×§×•××."""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
objects = identify_objects("photo.jpg")
print(objects)
```

×“×•×’××” 2: × ×™×ª×•×— ×¡× ×˜×™×× ×˜ ×•×™×–×•××œ×™
---------------------------------

```python
def analyze_visual_sentiment(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """× ×ª×— ××ª ×”×¡× ×˜×™×× ×˜ ×©×œ ×”×ª××•× ×”.
××” ×”×¨×’×© ×©×”×ª××•× ×” ××¢×‘×™×¨×”?
×”×× ×”×™× ×—×™×•×‘×™×ª, ×©×œ×™×œ×™×ª ××• × ×™×˜×¨×œ×™×ª?"""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
sentiment = analyze_visual_sentiment("photo.jpg")
print(sentiment)
```

×“×•×’××” 3: × ×™×ª×•×— ×˜×§×¡×˜ ×‘×ª××•× ×” (OCR)
-----------------------------------

```python
def extract_text_from_image(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×§×¨× ××ª ×›×œ ×”×˜×§×¡×˜ ×‘×ª××•× ×”.
×”×—×–×¨ ××ª ×”×˜×§×¡×˜ ×‘×¤×•×¨××˜ × ×§×™ ×•×××•×¨×’×Ÿ."""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
text = extract_text_from_image("document.jpg")
print(text)
```

×“×•×’××” 4: ×”×©×•×•××ª ×ª××•× ×•×ª
-------------------------

```python
def compare_images(image1_path, image2_path):
    img1 = PIL.Image.open(image1_path)
    img2 = PIL.Image.open(image2_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×”×©×•×•×” ×‘×™×Ÿ ×©×ª×™ ×”×ª××•× ×•×ª.
××” ×”×“××™×•×Ÿ ×•×”×©×•× ×™ ×‘×™× ×™×”×Ÿ?"""
    
    response = model.generate_content([prompt, img1, img2])
    return response.text

# ×©×™××•×©
comparison = compare_images("photo1.jpg", "photo2.jpg")
print(comparison)
```

×“×•×’××” 5: × ×™×ª×•×— ××•×¦×¨ ×‘×ª××•× ×”
-----------------------------

```python
def analyze_product(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """× ×ª×— ××ª ×”××•×¦×¨ ×‘×ª××•× ×”.
×›×œ×•×œ:
- ×©× ×”××•×¦×¨
- ×ª×›×•× ×•×ª ×¢×™×§×¨×™×•×ª
- ××™×›×•×ª × ×¨××™×ª
- ×”×¢×¨×›×” ×›×œ×œ×™×ª"""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
analysis = analyze_product("product.jpg")
print(analysis)
```

×“×•×’××” 6: ×–×™×”×•×™ ×× ×©×™× ×•×¤×¢×™×œ×•×™×•×ª
----------------------------------

```python
def identify_people_and_activities(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×–×”×” ×× ×©×™× ×•×¤×¢×™×œ×•×™×•×ª ×‘×ª××•× ×”.
×ª××¨ ××” ×›×œ ××“× ×¢×•×©×”."""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
description = identify_people_and_activities("event.jpg")
print(description)
```

×“×•×’××” 7: × ×™×ª×•×— × ×•×£
--------------------

```python
def analyze_landscape(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """× ×ª×— ××ª ×”× ×•×£ ×‘×ª××•× ×”.
×›×œ×•×œ:
- ×¡×•×’ × ×•×£
- ××œ×× ×˜×™× ×¢×™×§×¨×™×™×
- ×ª× ××™ ××–×’ ××•×•×™×¨
- ×©×¢×” ×‘×™×•× (×× × ×™×ª×Ÿ ×œ×–×”×•×ª)"""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
landscape = analyze_landscape("landscape.jpg")
print(landscape)
```

×“×•×’××” 8: ×™×¦×™×¨×ª ×ª×™××•×¨ ×©×™×•×•×§×™
-------------------------------

```python
def create_marketing_description(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×¦×•×¨ ×ª×™××•×¨ ×©×™×•×•×§×™ ××§×¦×•×¢×™ ×œ×ª××•× ×”.
×”×ª×™××•×¨ ×¦×¨×™×š ×œ×”×™×•×ª:
- ××©×›× ×¢
- ×××•×§×“ ×‘-benefits
- ××ª××™× ×œ×§×”×œ ×¨×—×‘"""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
marketing_text = create_marketing_description("product.jpg")
print(marketing_text)
```

×“×•×’××” 9: ×–×™×”×•×™ ×‘×¢×™×•×ª/× ×–×§×™×
-----------------------------

```python
def identify_issues(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """×–×”×” ×‘×¢×™×•×ª ××• × ×–×§×™× ×‘×ª××•× ×”.
×ª××¨ ××” ×”×‘×¢×™×” ×•××™×¤×” ×”×™× × ××¦××ª."""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
issues = identify_issues("damage.jpg")
print(issues)
```

×“×•×’××” 10: × ×™×ª×•×— ××¨×›×™×˜×§×˜×•×¨×”
-----------------------------

```python
def analyze_architecture(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = """× ×ª×— ××ª ×”××¨×›×™×˜×§×˜×•×¨×” ×‘×ª××•× ×”.
×›×œ×•×œ:
- ×¡×’× ×•×Ÿ ××¨×›×™×˜×§×˜×•× ×™
- ××œ×× ×˜×™× ×¢×™×¦×•×‘×™×™×
- ×ª×§×•×¤×” ××©×•×¢×¨×ª
- ×××¤×™×™× ×™× ××™×•×—×“×™×"""
    
    response = model.generate_content([prompt, img])
    return response.text

# ×©×™××•×©
architecture = analyze_architecture("building.jpg")
print(architecture)
```

×¢×‘×•×“×” ×¢× ×ª××•× ×•×ª ××¨×•×‘×•×ª
========================

```python
def analyze_multiple_images(image_paths, question):
    images = [PIL.Image.open(path) for path in image_paths]
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    content = [question] + images
    response = model.generate_content(content)
    return response.text

# ×©×™××•×©
images = ["img1.jpg", "img2.jpg", "img3.jpg"]
analysis = analyze_multiple_images(
    images,
    "××” ×”××©×•×ª×£ ×œ×›×œ ×”×ª××•× ×•×ª?"
)
print(analysis)
```

×©×™×œ×•×‘ ×¢× JSON Mode
===================

```python
def analyze_image_structured(image_path):
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel(
        "gemini-1.5-pro-vision",
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": {
                "type": "object",
                "properties": {
                    "description": {"type": "string"},
                    "objects": {
                        "type": "array",
                        "items": {"type": "string"}
                    },
                    "colors": {
                        "type": "array",
                        "items": {"type": "string"}
                    },
                    "sentiment": {"type": "string"}
                },
                "required": ["description", "objects"]
            }
        }
    )
    
    response = model.generate_content([
        "× ×ª×— ××ª ×”×ª××•× ×” ×‘×¤×™×¨×•×˜",
        img
    ])
    
    return json.loads(response.text)

# ×©×™××•×©
result = analyze_image_structured("photo.jpg")
print(result["description"])
print(result["objects"])
```

Best Practices
==============

1. ××™×›×•×ª ×ª××•× ×”
---------------
â€¢ ×”×©×ª××© ×‘×ª××•× ×•×ª ×‘××™×›×•×ª ×˜×•×‘×”
â€¢ ×•×“× ×©×”×ª××•× ×” ×‘×¨×•×¨×”
â€¢ ×”×™×× ×¢ ××ª××•× ×•×ª ××˜×•×©×˜×©×•×ª

2. ×¤×•×¨××˜×™× × ×ª××›×™×
-------------------
â€¢ JPEG
â€¢ PNG
â€¢ WebP
â€¢ GIF (frame ×¨××©×•×Ÿ)

3. ×’×•×“×œ ×ª××•× ×”
--------------
â€¢ ××§×¡×™××•×: 20MB
â€¢ ××•××œ×¥: ×¤×—×•×ª ×-5MB
â€¢ ×¨×–×•×œ×•×¦×™×”: ×¢×“ 3072x3072

4. ×©××œ×•×ª ×‘×¨×•×¨×•×ª
-----------------
â€¢ ×©××œ ×©××œ×•×ª ×¡×¤×¦×™×¤×™×•×ª
â€¢ ×”×•×¡×£ ×”×§×©×¨ ×›×©×¦×¨×™×š
â€¢ ×”×©×ª××© ×‘×©×¤×” ×‘×¨×•×¨×”

5. ×˜×™×¤×•×œ ×‘×©×’×™××•×ª
-----------------
```python
def safe_image_analysis(image_path, prompt):
    try:
        img = PIL.Image.open(image_path)
        model = genai.GenerativeModel("gemini-1.5-pro-vision")
        response = model.generate_content([prompt, img])
        return response.text
    except FileNotFoundError:
        return "×§×•×‘×¥ ×ª××•× ×” ×œ× × ××¦×"
    except Exception as e:
        return f"×©×’×™××”: {e}"

# ×©×™××•×©
result = safe_image_analysis("photo.jpg", "×ª××¨ ××ª ×”×ª××•× ×”")
```

×¡×™×›×•×
======

Image Understanding ×××¤×©×¨:
âœ“ ×–×™×”×•×™ ××•×‘×™×™×§×˜×™×
âœ“ ×ª×™××•×¨ ×ª××•× ×•×ª
âœ“ ×©××œ×•×ª ×¢×œ ×ª××•× ×•×ª
âœ“ × ×™×ª×•×— ×•×™×–×•××œ×™
âœ“ ×¢×‘×•×“×” ×¢× ×ª××•× ×•×ª ××¨×•×‘×•×ª
âœ“ ×©×™×œ×•×‘ ×¢× JSON Mode

Best Practices:
â€¢ ××™×›×•×ª ×ª××•× ×” ×˜×•×‘×”
â€¢ ×¤×•×¨××˜×™× × ×ª××›×™×
â€¢ ×’×•×“×œ ××ª××™×
â€¢ ×©××œ×•×ª ×‘×¨×•×¨×•×ª
â€¢ ×˜×™×¤×•×œ ×‘×©×’×™××•×ª

×‘×©×™×¢×•×¨ ×”×‘×: Safety Settings! ğŸš€

---
Â© 2026 Google AI Academy
Image Understanding - ×”××“×¨×™×š ×”×©×œ×