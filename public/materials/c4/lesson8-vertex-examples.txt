דוגמאות קוד ל-Vertex AI
=========================

אוסף דוגמאות מעשיות
=====================

דוגמה 1: שימוש בסיסי
======================

```python
import vertexai
from vertexai.generative_models import GenerativeModel

# אתחל
vertexai.init(project="your-project-id", location="us-central1")

# צור מודל
model = GenerativeModel("gemini-1.5-pro")

# יצירת תוכן
response = model.generate_content("מה זה Python?")
print(response.text)
```

דוגמה 2: עם Configuration
===========================

```python
from vertexai.generative_models import GenerativeModel, GenerationConfig

model = GenerativeModel("gemini-1.5-pro")

config = GenerationConfig(
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    max_output_tokens=2000
)

response = model.generate_content(
    "כתוב סיפור",
    generation_config=config
)
print(response.text)
```

דוגמה 3: Chat
===============

```python
model = GenerativeModel("gemini-1.5-pro")
chat = model.start_chat()

# הודעה ראשונה
response = chat.send_message("מה זה AI?")
print(response.text)

# הודעה שנייה
response = chat.send_message("תן לי דוגמה")
print(response.text)
```

דוגמה 4: עבודה עם תמונות
===========================

```python
from vertexai.generative_models import GenerativeModel, Part

model = GenerativeModel("gemini-1.5-pro-vision")

# תמונה מ-GCS
image_part = Part.from_uri(
    uri="gs://your-bucket/image.jpg",
    mime_type="image/jpeg"
)

response = model.generate_content([image_part, "תאר את התמונה"])
print(response.text)
```

דוגמה 5: JSON Mode
===================

```python
from vertexai.generative_models import GenerativeModel, Schema

model = GenerativeModel("gemini-1.5-pro")

response_schema = Schema(
    type=Schema.Type.OBJECT,
    properties={
        "name": Schema(type=Schema.Type.STRING),
        "age": Schema(type=Schema.Type.NUMBER)
    },
    required=["name", "age"]
)

response = model.generate_content(
    "צור פרופיל משתמש",
    generation_config={"response_schema": response_schema}
)
print(response.text)
```

דוגמה 6: Batch Processing
===========================

```python
def process_batch(prompts):
    model = GenerativeModel("gemini-1.5-pro")
    results = []
    
    for prompt in prompts:
        response = model.generate_content(prompt)
        results.append(response.text)
    
    return results

# שימוש
prompts = ["מה זה Python?", "מה זה JavaScript?"]
results = process_batch(prompts)
for prompt, result in zip(prompts, results):
    print(f"{prompt}: {result}")
```

דוגמה 7: עם Error Handling
============================

```python
import time

def safe_generate(model, prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return {"success": True, "text": response.text}
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            return {"success": False, "error": str(e)}
    return {"success": False, "error": "נכשל אחרי כל הניסיונות"}

# שימוש
model = GenerativeModel("gemini-1.5-pro")
result = safe_generate(model, "טקסט")
if result["success"]:
    print(result["text"])
else:
    print(f"שגיאה: {result['error']}")
```

דוגמה 8: מערכת עם Caching
===========================

```python
import hashlib
import json
import os

CACHE_DIR = "vertex_cache"

def get_cache_key(prompt):
    return hashlib.md5(prompt.encode()).hexdigest()

def get_cached(prompt):
    if not os.path.exists(CACHE_DIR):
        return None
    
    cache_key = get_cache_key(prompt)
    cache_path = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    if os.path.exists(cache_path):
        with open(cache_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def cache_result(prompt, result):
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)
    
    cache_key = get_cache_key(prompt)
    cache_path = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    with open(cache_path, "w", encoding="utf-8") as f:
        json.dump({"prompt": prompt, "result": result}, f, ensure_ascii=False)

def generate_with_cache(model, prompt):
    cached = get_cached(prompt)
    if cached:
        return cached["result"]
    
    response = model.generate_content(prompt)
    result = response.text
    cache_result(prompt, result)
    return result

# שימוש
model = GenerativeModel("gemini-1.5-pro")
result = generate_with_cache(model, "מה זה AI?")
print(result)
```

דוגמה 9: מערכת מולטי-מודאלית
===============================

```python
from vertexai.generative_models import GenerativeModel, Part

model = GenerativeModel("gemini-1.5-pro-vision")

# טקסט ותמונה
text = "זה מוצר חדש"
image_part = Part.from_uri(
    uri="gs://your-bucket/product.jpg",
    mime_type="image/jpeg"
)

prompt = f"{text}\n\nנתח את המוצר בתמונה."
response = model.generate_content([prompt, image_part])
print(response.text)
```

דוגמה 10: מערכת עם Monitoring
================================

```python
import logging
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MonitoredModel:
    def __init__(self, model_name):
        self.model = GenerativeModel(model_name)
        self.request_count = 0
        self.error_count = 0
        self.total_time = 0
    
    def generate_content(self, prompt):
        start_time = time.time()
        self.request_count += 1
        
        try:
            response = self.model.generate_content(prompt)
            duration = time.time() - start_time
            self.total_time += duration
            
            logger.info(f"בקשה #{self.request_count} הושלמה ב-{duration:.2f} שניות")
            return response.text
        except Exception as e:
            self.error_count += 1
            logger.error(f"שגיאה בבקשה #{self.request_count}: {e}")
            raise
    
    def get_stats(self):
        avg_time = self.total_time / self.request_count if self.request_count > 0 else 0
        return {
            "total_requests": self.request_count,
            "errors": self.error_count,
            "success_rate": (self.request_count - self.error_count) / self.request_count if self.request_count > 0 else 0,
            "avg_time": avg_time
        }

# שימוש
monitored_model = MonitoredModel("gemini-1.5-pro")
result = monitored_model.generate_content("טקסט")
print(result)
stats = monitored_model.get_stats()
print(f"סטטיסטיקות: {stats}")
```

סיכום
======

דוגמאות מעשיות:
✓ שימוש בסיסי
✓ Configuration
✓ Chat
✓ תמונות
✓ JSON Mode
✓ Batch Processing
✓ Error Handling
✓ Caching
✓ מולטי-מודאלי
✓ Monitoring

כל הדוגמאות כוללות:
• קוד מלא
• הסברים
• שימוש מעשי

---
© 2026 Google AI Academy
דוגמאות קוד ל-Vertex AI