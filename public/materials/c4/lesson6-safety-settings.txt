Safety Settings - ×”××“×¨×™×š ×”×©×œ×
================================

×©×™×¢×•×¨ 6: Safety Settings
==========================

××” ×”×Ÿ Safety Settings?
=======================

Safety Settings ×”×Ÿ ×”×’×“×¨×•×ª ×©××’× ×•×ª ××¤× ×™ ×ª×•×›×Ÿ ×œ× ×”×•×œ×:
â€¢ Hate Speech - ×©× ××”
â€¢ Harassment - ×”×˜×¨×“×”
â€¢ Sexually Explicit - ×ª×•×›×Ÿ ××™× ×™
â€¢ Dangerous Content - ×ª×•×›×Ÿ ××¡×•×›×Ÿ

×œ××” ×–×” ×—×©×•×‘?
=============

â€¢ ×”×’× ×” ×¢×œ ××©×ª××©×™×
â€¢ ×× ×™×¢×ª ×ª×•×›×Ÿ ×¤×•×’×¢× ×™
â€¢ ×©××™×¨×” ×¢×œ ×¡×˜× ×“×¨×˜×™×
â€¢ ×™×¦×™×¨×ª ×¡×‘×™×‘×” ×‘×˜×•×—×”

×¨××•×ª ×”×’× ×”
==========

1. Block None
-------------
â€¢ ×œ×œ× ×—×¡×™××”
â€¢ ××ª××™× ×œ×‘×“×™×§×•×ª
â€¢ ×œ× ××•××œ×¥ ×œ×¤×¨×•×“×§×©×Ÿ

2. Block Few
-------------
â€¢ ×—×¡×™××” ××™× ×™××œ×™×ª
â€¢ ×¨×§ ×ª×•×›×Ÿ ×§×™×¦×•× ×™ ×××•×“
â€¢ ×œ× ××•××œ×¥ ×œ×¨×•×‘ ×”×©×™××•×©×™×

3. Block Some (×‘×¨×™×¨×ª ××—×“×œ)
----------------------------
â€¢ ×—×¡×™××” ×××•×–× ×ª
â€¢ ××•××œ×¥ ×œ×¨×•×‘ ×”×©×™××•×©×™×
â€¢ ××™×–×•×Ÿ ×‘×™×Ÿ ×‘×˜×™×—×•×ª ×œ×©×™××•×©×™×•×ª

4. Block Most
--------------
â€¢ ×—×¡×™××” ××§×¡×™××œ×™×ª
â€¢ ××ª××™× ×œ××¤×œ×™×§×¦×™×•×ª ×œ×™×œ×“×™×
â€¢ ×¢×œ×•×œ ×œ×—×¡×•× ×ª×•×›×Ÿ ×œ×’×™×˜×™××™

×”×’×“×¨×ª Safety Settings
=======================

Python:
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

safety_settings = [
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    }
]

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    safety_settings=safety_settings
)

response = model.generate_content("×˜×§×¡×˜ ×œ×‘×§×©×”")
print(response.text)
```

JavaScript:
```javascript
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI("YOUR_API_KEY");
const model = genAI.getGenerativeModel({
    model: "gemini-1.5-flash",
    safetySettings: [
        {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
        },
        {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
        },
        {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
        },
        {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
        }
    ]
});

const result = await model.generateContent("×˜×§×¡×˜ ×œ×‘×§×©×”");
console.log(result.response.text());
```

×§×•× ×¤×™×’×•×¨×¦×™×•×ª ××•××œ×¦×•×ª
======================

1. ××¤×œ×™×§×¦×™×” ×›×œ×œ×™×ª
------------------
```python
safety_settings = [
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"  # Block Some
    },
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    }
]
```

2. ××¤×œ×™×§×¦×™×” ×œ×™×œ×“×™×
--------------------
```python
safety_settings = [
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_ONLY_HIGH"  # Block Most
    },
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_ONLY_HIGH"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_ONLY_HIGH"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_ONLY_HIGH"
    }
]
```

3. ××¤×œ×™×§×¦×™×” ××§×¦×•×¢×™×ª/×˜×›× ×™×ª
----------------------------
```python
safety_settings = [
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE"  # Allow for technical content
    },
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    }
]
```

×˜×™×¤×•×œ ×‘-Safety Blocks
=====================

×›×©×”××•×“×œ ×—×•×¡× ×ª×•×›×Ÿ, ×ª×§×‘×œ ×ª×’×•×‘×” ××™×•×—×“×ª:

```python
def safe_generate(model, prompt):
    try:
        response = model.generate_content(prompt)
        
        # ×‘×“×•×§ ×× ×™×© safety blocks
        if response.candidates[0].finish_reason == "SAFETY":
            return {
                "blocked": True,
                "reason": "×ª×•×›×Ÿ × ×—×¡× ×¢×œ ×™×“×™ Safety Settings",
                "safety_ratings": response.candidates[0].safety_ratings
            }
        
        return {
            "blocked": False,
            "text": response.text
        }
    except Exception as e:
        return {
            "blocked": False,
            "error": str(e)
        }

# ×©×™××•×©
result = safe_generate(model, "×˜×§×¡×˜ ×œ×‘×§×©×”")
if result["blocked"]:
    print("×ª×•×›×Ÿ × ×—×¡×")
    print(result["reason"])
else:
    print(result["text"])
```

×‘×“×™×§×ª Safety Ratings
=====================

```python
def check_safety_ratings(response):
    """×‘×“×•×§ safety ratings ×©×œ ×ª×’×•×‘×”"""
    if not response.candidates:
        return None
    
    candidate = response.candidates[0]
    if not hasattr(candidate, 'safety_ratings'):
        return None
    
    ratings = {}
    for rating in candidate.safety_ratings:
        category = rating.category.name
        probability = rating.probability.name
        ratings[category] = probability
    
    return ratings

# ×©×™××•×©
response = model.generate_content("×˜×§×¡×˜")
ratings = check_safety_ratings(response)
if ratings:
    print("Safety Ratings:")
    for category, probability in ratings.items():
        print(f"  {category}: {probability}")
```

Best Practices
==============

1. ×”×ª×× ×œ×¤×™ use case
---------------------
â€¢ ××¤×œ×™×§×¦×™×” ×›×œ×œ×™×ª: Block Some
â€¢ ××¤×œ×™×§×¦×™×” ×œ×™×œ×“×™×: Block Most
â€¢ ××¤×œ×™×§×¦×™×” ×˜×›× ×™×ª: Block Few/None

2. ×‘×“×•×§ ×ª×’×•×‘×•×ª
----------------
â€¢ ×‘×“×•×§ safety ratings
â€¢ ×˜×™×¤×•×œ ×‘-blocks
â€¢ ×œ×•×’ errors

3. ×¢×“×›×Ÿ ×œ×¤×™ ×¦×•×¨×š
------------------
â€¢ ×”×ª×× ×œ×¤×™ feedback
â€¢ ×©×¤×¨ ×‘×”×“×¨×’×”
â€¢ ×ª×™×¢×“ ×©×™× ×•×™×™×

4. ×©×§×™×¤×•×ª
-----------
â€¢ ×”×¡×‘×¨ ×œ××©×ª××©×™×
â€¢ ×ª×Ÿ feedback ×¢×œ blocks
â€¢ ×”×¦×’ alternatives

×“×•×’×××•×ª ××¢×©×™×•×ª
================

×“×•×’××” 1: ×¦'××˜×‘×•×˜ ×›×œ×œ×™
-----------------------
```python
def create_safe_chatbot():
    safety_settings = [
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        }
    ]
    
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        safety_settings=safety_settings
    )
```

×“×•×’××” 2: ××¢×¨×›×ª ×—×™× ×•×›×™×ª
-------------------------
```python
def create_educational_model():
    safety_settings = [
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_ONLY_HIGH"
        },
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_ONLY_HIGH"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_ONLY_HIGH"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_ONLY_HIGH"
        }
    ]
    
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        safety_settings=safety_settings
    )
```

×“×•×’××” 3: ××¢×¨×›×ª ×˜×›× ×™×ª
----------------------
```python
def create_technical_model():
    safety_settings = [
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_NONE"  # Allow technical discussions
        },
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        }
    ]
    
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        safety_settings=safety_settings
    )
```

×¡×™×›×•×
======

Safety Settings ×××¤×©×¨×•×ª:
âœ“ ×”×’× ×” ××¤× ×™ ×ª×•×›×Ÿ ×œ× ×”×•×œ×
âœ“ ×”×ª×××” ×œ×¤×™ use case
âœ“ ×©×œ×™×˜×” ×¢×œ ×¨××ª ×”×’× ×”
âœ“ ×™×¦×™×¨×ª ×¡×‘×™×‘×” ×‘×˜×•×—×”

×¨××•×ª ×”×’× ×”:
â€¢ Block None - ×œ×œ× ×—×¡×™××”
â€¢ Block Few - ××™× ×™××œ×™
â€¢ Block Some - ×××•×–×Ÿ (××•××œ×¥)
â€¢ Block Most - ××§×¡×™××œ×™

Best Practices:
â€¢ ×”×ª×× ×œ×¤×™ use case
â€¢ ×‘×“×•×§ ×ª×’×•×‘×•×ª
â€¢ ×¢×“×›×Ÿ ×œ×¤×™ ×¦×•×¨×š
â€¢ ×©×§×™×¤×•×ª

×‘×©×™×¢×•×¨ ×”×‘×: cURL, Python, JavaScript! ğŸš€

---
Â© 2026 Google AI Academy
Safety Settings - ×”××“×¨×™×š ×”×©×œ×