דוגמאות Python ל-Gemini API
=============================

אוסף דוגמאות מעשיות
=====================

דוגמה 1: צ'אטבוט בסיסי
========================

```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

def create_chatbot():
    """צור צ'אטבוט בסיסי"""
    model = genai.GenerativeModel("gemini-1.5-flash")
    chat = model.start_chat(history=[])
    return chat

def chat(chat_session, message):
    """שלח הודעה לצ'אטבוט"""
    response = chat_session.send_message(message)
    return response.text

# שימוש
chatbot = create_chatbot()
while True:
    user_input = input("אתה: ")
    if user_input.lower() == "exit":
        break
    response = chat(chatbot, user_input)
    print(f"בוט: {response}")
```

דוגמה 2: מערכת סיכום טקסט
=============================

```python
def summarize_text(text, max_length=200):
    """סכם טקסט"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "temperature": 0.2,
            "max_output_tokens": max_length
        }
    )
    
    prompt = f"סכם את הטקסט הבא בקצרה:\n\n{text}"
    response = model.generate_content(prompt)
    return response.text

# שימוש
long_text = "טקסט ארוך מאוד..."
summary = summarize_text(long_text)
print(summary)
```

דוגמה 3: מתרגם
================

```python
def translate_text(text, target_language="English"):
    """תרגם טקסט"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "temperature": 0.1,
            "max_output_tokens": 2000
        },
        system_instruction="אתה מתרגם מקצועי. תרגם בצורה מדויקת תוך שמירה על טון ומשמעות."
    )
    
    prompt = f"תרגם את הטקסט הבא ל-{target_language}:\n\n{text}"
    response = model.generate_content(prompt)
    return response.text

# שימוש
hebrew_text = "שלום עולם"
english_text = translate_text(hebrew_text, "English")
print(english_text)
```

דוגמה 4: ניתוח סנטימנט
=========================

```python
import json

def analyze_sentiment(text):
    """נתח סנטימנט של טקסט"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": {
                "type": "object",
                "properties": {
                    "sentiment": {
                        "type": "string",
                        "enum": ["positive", "negative", "neutral"]
                    },
                    "confidence": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1
                    },
                    "key_phrases": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "required": ["sentiment", "confidence"]
            }
        }
    )
    
    prompt = f"נתח את הסנטימנט של הטקסט הבא:\n\n{text}"
    response = model.generate_content(prompt)
    return json.loads(response.text)

# שימוש
text = "המוצר הזה מעולה! אני מאוד מרוצה."
sentiment = analyze_sentiment(text)
print(f"סנטימנט: {sentiment['sentiment']}")
print(f"ביטחון: {sentiment['confidence']}")
```

דוגמה 5: מחולל קוד
====================

```python
def generate_code(language, description):
    """צור קוד לפי תיאור"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "temperature": 0.2,
            "max_output_tokens": 4000
        },
        system_instruction=f"אתה מפתח {language} מנוסה. כתוב קוד נקי ומתועד."
    )
    
    prompt = f"כתוב קוד {language} ש-{description}"
    response = model.generate_content(prompt)
    return response.text

# שימוש
code = generate_code("Python", "מחשב ממוצע של רשימת מספרים")
print(code)
```

דוגמה 6: ניתוח תמונה
=======================

```python
import PIL.Image

def analyze_image(image_path, question="תאר את התמונה"):
    """נתח תמונה"""
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    response = model.generate_content([question, img])
    return response.text

# שימוש
description = analyze_image("photo.jpg", "מה יש בתמונה?")
print(description)
```

דוגמה 7: מערכת Q&A
=====================

```python
def create_qa_system(context):
    """צור מערכת שאלות ותשובות"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        system_instruction=f"""אתה עוזר AI שמשיב על שאלות בהתבסס על הקשר הבא:
{context}

תמיד תן תשובות מדויקות ומבוססות על הקשר."""
    )
    return model

def ask_question(model, question):
    """שאל שאלה"""
    response = model.generate_content(question)
    return response.text

# שימוש
context = "Python היא שפת תכנות פופולרית..."
qa_model = create_qa_system(context)
answer = ask_question(qa_model, "מה זה Python?")
print(answer)
```

דוגמה 8: מחולל תוכן
=====================

```python
def generate_content(content_type, topic, style="professional"):
    """צור תוכן לפי סוג ונושא"""
    model = genai.GenerativeModel(
        "gemini-1.5-flash",
        generation_config={
            "temperature": 0.8 if style == "creative" else 0.6,
            "max_output_tokens": 2000
        },
        system_instruction=f"אתה כותב תוכן מקצועי. כתוב בסגנון {style}."
    )
    
    prompt = f"צור {content_type} על הנושא: {topic}"
    response = model.generate_content(prompt)
    return response.text

# שימוש
blog_post = generate_content("פוסט בלוג", "AI", "creative")
print(blog_post)
```

דוגמה 9: מערכת עם Retry
==========================

```python
import time

def generate_with_retry(model, prompt, max_retries=3):
    """יצירת תוכן עם retry logic"""
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            return {"success": True, "text": response.text}
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # Exponential backoff
                print(f"נכשל, מנסה שוב בעוד {wait_time} שניות...")
                time.sleep(wait_time)
                continue
            return {"success": False, "error": str(e)}
    return {"success": False, "error": "נכשל אחרי כל הניסיונות"}

# שימוש
model = genai.GenerativeModel("gemini-1.5-flash")
result = generate_with_retry(model, "טקסט לבקשה")
if result["success"]:
    print(result["text"])
else:
    print(f"שגיאה: {result['error']}")
```

דוגמה 10: מערכת Batch Processing
===================================

```python
def process_batch(prompts, model):
    """עבד על מספר בקשות"""
    results = []
    for prompt in prompts:
        try:
            response = model.generate_content(prompt)
            results.append({
                "prompt": prompt,
                "result": response.text,
                "success": True
            })
        except Exception as e:
            results.append({
                "prompt": prompt,
                "error": str(e),
                "success": False
            })
    return results

# שימוש
prompts = [
    "מה זה Python?",
    "מה זה JavaScript?",
    "מה זה AI?"
]
model = genai.GenerativeModel("gemini-1.5-flash")
results = process_batch(prompts, model)
for result in results:
    if result["success"]:
        print(f"{result['prompt']}: {result['result']}")
    else:
        print(f"שגיאה ב-{result['prompt']}: {result['error']}")
```

דוגמה 11: מערכת עם Caching
=============================

```python
import hashlib
import json
import os

CACHE_DIR = "api_cache"

def get_cache_key(prompt):
    """קבל מפתח cache"""
    return hashlib.md5(prompt.encode()).hexdigest()

def get_cached(prompt):
    """קבל מ-cache"""
    if not os.path.exists(CACHE_DIR):
        return None
    
    cache_key = get_cache_key(prompt)
    cache_path = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    if os.path.exists(cache_path):
        with open(cache_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def cache_result(prompt, result):
    """שמור ב-cache"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)
    
    cache_key = get_cache_key(prompt)
    cache_path = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    with open(cache_path, "w", encoding="utf-8") as f:
        json.dump({"prompt": prompt, "result": result}, f, ensure_ascii=False)

def generate_with_cache(model, prompt):
    """יצירת תוכן עם cache"""
    cached = get_cached(prompt)
    if cached:
        return cached["result"]
    
    response = model.generate_content(prompt)
    result = response.text
    cache_result(prompt, result)
    return result

# שימוש
model = genai.GenerativeModel("gemini-1.5-flash")
result = generate_with_cache(model, "מה זה AI?")
print(result)
```

דוגמה 12: מערכת מולטי-מודאלית
=================================

```python
def analyze_multimodal(text, image_path):
    """נתח טקסט ותמונה יחד"""
    img = PIL.Image.open(image_path)
    model = genai.GenerativeModel("gemini-1.5-pro-vision")
    
    prompt = f"""נתח את הטקסט והתמונה הבאים:
    
טקסט: {text}
תמונה: [תמונה מצורפת]

מה הקשר ביניהם?"""
    
    response = model.generate_content([prompt, img])
    return response.text

# שימוש
analysis = analyze_multimodal("זה מוצר חדש", "product.jpg")
print(analysis)
```

סיכום
======

דוגמאות מעשיות:
✓ צ'אטבוט בסיסי
✓ סיכום טקסט
✓ תרגום
✓ ניתוח סנטימנט
✓ מחולל קוד
✓ ניתוח תמונה
✓ מערכת Q&A
✓ מחולל תוכן
✓ Retry logic
✓ Batch processing
✓ Caching
✓ מולטי-מודאלי

כל הדוגמאות כוללות:
• קוד מלא
• הסברים
• שימוש מעשי

---
© 2026 Google AI Academy
דוגמאות Python ל-Gemini API