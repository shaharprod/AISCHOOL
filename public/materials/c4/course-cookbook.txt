Google AI Studio Cookbook
===========================

××ª×›×•× ×™× ×•×“×•×’×××•×ª ××¢×©×™×•×ª
=========================

ğŸ‘¨â€ğŸ³ ××‘×•×
===========

×”-Cookbook ×”×–×” ××›×™×œ ××ª×›×•× ×™× ××•×›× ×™× ×œ×©×™××•×© ×¢× Gemini API.
×›×œ "××ª×›×•×Ÿ" ×›×•×œ×œ: ×‘×¢×™×”, ×¤×ª×¨×•×Ÿ, ×§×•×“ ××œ×.

××” ×ª××¦× ×›××Ÿ:
------------
âœ“ 25+ ×“×•×’×××•×ª ××¢×©×™×•×ª
âœ“ ×§×•×“ ××œ× ×•×¢×•×‘×“
âœ“ ×”×¡×‘×¨×™× ××¤×•×¨×˜×™×
âœ“ Tips & Tricks
âœ“ Best Practices

××ª×™ ×œ×”×©×ª××©?
------------
â€¢ ×œ×•××“×™× API ×—×“×©
â€¢ ×¦×¨×™×›×™× ×”×©×¨××”
â€¢ ×¨×•×¦×™× ×”×ª×—×œ×” ××”×™×¨×”
â€¢ ×‘×•× ×™× POC

××‘× ×” ××ª×›×•×Ÿ
===========

×›×œ ××ª×›×•×Ÿ ×›×•×œ×œ:

1. **×©× ×”××ª×›×•×Ÿ** ğŸ•
2. **××” ×–×” ×¤×•×ª×¨** (Use Case)
3. **×“×¨×™×©×•×ª** (Requirements)
4. **×§×•×“ ××œ×** (Full Code)
5. **×”×¡×‘×¨** (Explanation)
6. **×˜×™×¤×™×** (Tips)
7. **×•×¨×™××¦×™×•×ª** (Variations)

×§×˜×’×•×¨×™×•×ª
==========

1. Basic Usage
2. Content Generation
3. Analysis
4. Multimodal
5. Advanced
6. Integration
7. Production

××ª×›×•×Ÿ 1: "Hello Gemini" ğŸ‘‹
===========================

Use Case:
---------
×”×‘× ×™×™×” ×¨××©×•× ×” ×©×œ API - ×©×œ×™×—×ª ×¤×¨×•××¤×˜ ×¤×©×•×˜

Requirements:
-------------
```
pip install google-generativeai
```

Code:
-----
```python
import google.generativeai as genai

# ×”×’×“×¨×ª API Key
genai.configure(api_key="YOUR_API_KEY")

# ×™×¦×™×¨×ª ××•×“×œ
model = genai.GenerativeModel('gemini-1.5-flash')

# ×©×œ×™×—×ª ×¤×¨×•××¤×˜
response = model.generate_content("Write a hello world in Python")

# ×”×“×¤×¡×ª ×ª×©×•×‘×”
print(response.text)
```

×”×¡×‘×¨:
------
1. ×™×™×‘×•× ×”×¡×¤×¨×™×™×”
2. ×”×’×“×¨×ª ××¤×ª×—
3. ×‘×—×™×¨×ª ××•×“×œ
4. ×©×œ×™×—×ª ×‘×§×©×”
5. ×§×‘×œ×ª ×ª×©×•×‘×”

Tips:
-----
ğŸ’¡ ×©××•×¨ API Key ×‘-.env
ğŸ’¡ ×”×©×ª××© ×‘-flash ×œ××”×™×¨×•×ª
ğŸ’¡ Pro ×œ××•×¨×›×‘×•×ª

××ª×›×•×Ÿ 2: "Smart Chatbot" ğŸ’¬
============================

Use Case:
---------
×¦'××˜×‘×•×˜ ×¢× ×–×™×›×¨×•×Ÿ ×©×™×—×”

Code:
-----
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

# ××•×“×œ ×¢× ×”×™×¡×˜×•×¨×™×”
model = genai.GenerativeModel('gemini-1.5-flash')
chat = model.start_chat(history=[])

# ×¤×•× ×§×¦×™×” ×œ×©×™×—×”
def chat_with_bot(message):
    response = chat.send_message(message)
    return response.text

# ×“×•×’××ª ×©×™××•×©
print(chat_with_bot("Hi! My name is John"))
print(chat_with_bot("What's my name?"))  # ×™×–×›×•×¨!
```

×”×¡×‘×¨:
------
â€¢ `start_chat()` - ××ª×—×™×œ ×©×™×—×” ×¢× ×–×™×›×¨×•×Ÿ
â€¢ `history=[]` - ×”×™×¡×˜×•×¨×™×” ×¨×™×§×”
â€¢ ×›×œ `send_message` × ×©××¨ ×‘×”×™×¡×˜×•×¨×™×”

Tips:
-----
ğŸ’¡ ×©××•×¨ ×”×™×¡×˜×•×¨×™×” ×œ×¤×™ ××©×ª××©
ğŸ’¡ ××—×§ ×”×™×¡×˜×•×¨×™×” ×›×œ X ×”×•×“×¢×•×ª
ğŸ’¡ ×”×©×ª××© ×‘-System Instructions

××ª×›×•×Ÿ 3: "Content Generator" âœï¸
=================================

Use Case:
---------
×™×¦×™×¨×ª ×ª×•×›×Ÿ ××’×•×•×Ÿ (×¤×•×¡×˜×™×, ××™×™×œ×™×, ×•×›×•')

Code:
-----
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-pro')

def generate_content(type, topic, tone="professional"):
    prompts = {
        "blog": f"Write a blog post about {topic} in {tone} tone",
        "email": f"Write a professional email about {topic}",
        "social": f"Write a social media post about {topic}, max 280 chars",
        "ad": f"Write an ad copy for {topic}, persuasive and short"
    }
    
    prompt = prompts.get(type, f"Write about {topic}")
    response = model.generate_content(prompt)
    return response.text

# ×©×™××•×©
blog = generate_content("blog", "AI in healthcare", "friendly")
email = generate_content("email", "product launch")
tweet = generate_content("social", "new AI tool")

print(blog)
```

Tips:
-----
ğŸ’¡ ×”×•×¡×£ templates × ×•×¡×¤×™×
ğŸ’¡ ×©××•×¨ ×ª×•×¦××•×ª ×˜×•×‘×•×ª
ğŸ’¡ ×©×œ×‘ generation config

××ª×›×•×Ÿ 4: "Image Analyzer" ğŸ“·
==============================

Use Case:
---------
× ×™×ª×•×— ×ª××•× ×•×ª ×¢× ×©××œ×•×ª

Code:
-----
```python
import google.generativeai as genai
from PIL import Image

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-flash')

def analyze_image(image_path, question="What's in this image?"):
    img = Image.open(image_path)
    response = model.generate_content([question, img])
    return response.text

# ×©×™××•×©
result = analyze_image("product.jpg", "Describe this product")
print(result)

result2 = analyze_image("chart.png", "Explain this chart in simple terms")
print(result2)
```

Variations:
-----------
```python
# ××¡×¤×¨ ×ª××•× ×•×ª
images = [Image.open(f"img{i}.jpg") for i in range(1,4)]
response = model.generate_content(["Compare these images"] + images)

# ×ª××•× ×” + ×”×§×©×¨
response = model.generate_content([
    "This is our product design. Suggest improvements:",
    img,
    "Focus on: UX, colors, and accessibility"
])
```

××ª×›×•×Ÿ 5: "PDF Summarizer" ğŸ“„
==============================

Use Case:
---------
×¡×™×›×•× ××¡××›×™ PDF ××¨×•×›×™×

Code:
-----
```python
import google.generativeai as genai
import PyPDF2

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-pro')

def summarize_pdf(pdf_path, summary_length="medium"):
    # ×§×¨×™××ª PDF
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    
    # ×¡×™×›×•×
    lengths = {
        "short": "in 3 bullet points",
        "medium": "in 1 paragraph",
        "long": "in detail with key points"
    }
    
    prompt = f"Summarize this document {lengths[summary_length]}:\n\n{text}"
    response = model.generate_content(prompt)
    return response.text

# ×©×™××•×©
summary = summarize_pdf("report.pdf", "medium")
print(summary)
```

Tips:
-----
ğŸ’¡ ×—×œ×§ ××¡××›×™× ××¨×•×›×™× (>1M ×˜×•×§× ×™×)
ğŸ’¡ ×©××•×¨ ×¡×™×›×•× ×œ×§×•×‘×¥
ğŸ’¡ ×”×•×¡×£ extraction ×©×œ × ×§×•×“×•×ª ××¤×ª×—

××ª×›×•×Ÿ 6: "JSON Extractor" ğŸ”
==============================

Use Case:
---------
×—×™×œ×•×¥ ××™×“×¢ ××•×‘× ×” ××˜×§×¡×˜

Code:
-----
```python
import google.generativeai as genai
import json

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel(
    'gemini-1.5-flash',
    generation_config={"response_mime_type": "application/json"}
)

def extract_structured_data(text, schema):
    prompt = f"""
    Extract information from this text and return JSON following this schema:
    {schema}
    
    Text: {text}
    """
    
    response = model.generate_content(prompt)
    return json.loads(response.text)

# ×“×•×’××”
text = "John Doe, 35 years old, lives in New York, works as engineer at Google"
schema = {
    "name": "string",
    "age": "number",
    "city": "string",
    "occupation": "string",
    "company": "string"
}

data = extract_structured_data(text, schema)
print(json.dumps(data, indent=2))
```

Output:
-------
```json
{
  "name": "John Doe",
  "age": 35,
  "city": "New York",
  "occupation": "engineer",
  "company": "Google"
}
```

××ª×›×•×Ÿ 7: "Code Reviewer" ğŸ‘¨â€ğŸ’»
===============================

Use Case:
---------
×‘×™×§×•×¨×ª ×§×•×“ ××•×˜×•××˜×™×ª

Code:
-----
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

model = genai.GenerativeModel(
    'gemini-1.5-pro',
    system_instruction="""
    You are a senior code reviewer.
    Review code for:
    - Bugs and errors
    - Best practices
    - Performance issues
    - Security vulnerabilities
    - Code readability
    
    Provide specific, actionable feedback.
    """
)

def review_code(code, language="python"):
    prompt = f"Review this {language} code:\n\n```{language}\n{code}\n```"
    response = model.generate_content(prompt)
    return response.text

# ×©×™××•×©
code = '''
def calculate(x, y):
    return x/y
'''

review = review_code(code)
print(review)
```

××ª×›×•×Ÿ 8: "Multi-Language Translator" ğŸŒ
=========================================

Use Case:
---------
×ª×¨×’×•× ×œ×©×¤×•×ª ××¨×•×‘×•×ª ×‘×‘×ª ××—×ª

Code:
-----
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-flash')

def translate_multi(text, target_languages):
    langs = ", ".join(target_languages)
    prompt = f"""
    Translate this text to {langs}.
    Return as JSON: {{"language": "translated_text"}}
    
    Text: {text}
    """
    
    response = model.generate_content(
        prompt,
        generation_config={"response_mime_type": "application/json"}
    )
    
    return json.loads(response.text)

# ×©×™××•×©
translations = translate_multi(
    "Hello, how are you?",
    ["Spanish", "French", "Hebrew", "Japanese"]
)

for lang, text in translations.items():
    print(f"{lang}: {text}")
```

××ª×›×•×Ÿ 9: "Sentiment Analyzer" ğŸ˜ŠğŸ˜ğŸ˜¢
======================================

Use Case:
---------
× ×™×ª×•×— ×¡× ×˜×™×× ×˜ ×©×œ ×˜×§×¡×˜/×‘×™×§×•×¨×•×ª

Code:
-----
```python
import google.generativeai as genai
import json

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-flash')

def analyze_sentiment(text):
    prompt = f"""
    Analyze the sentiment of this text.
    Return JSON with:
    - sentiment: "positive", "negative", or "neutral"
    - confidence: 0-100
    - emotions: list of detected emotions
    - summary: brief explanation
    
    Text: {text}
    """
    
    response = model.generate_content(
        prompt,
        generation_config={"response_mime_type": "application/json"}
    )
    
    return json.loads(response.text)

# ×©×™××•×©
reviews = [
    "This product is amazing! Best purchase ever!",
    "Terrible quality. Waste of money.",
    "It's okay, nothing special."
]

for review in reviews:
    result = analyze_sentiment(review)
    print(f"Text: {review}")
    print(f"Sentiment: {result['sentiment']} ({result['confidence']}%)")
    print(f"Emotions: {', '.join(result['emotions'])}")
    print()
```

××ª×›×•×Ÿ 10: "RAG System" ğŸ“š
===========================

Use Case:
---------
Retrieval-Augmented Generation - ×©××œ×•×ª ×¢×œ ××¡××›×™×

Code:
-----
```python
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-1.5-pro')

class RAGSystem:
    def __init__(self, documents):
        self.documents = documents
        self.model = model
    
    def query(self, question):
        # ×‘× ×™×™×ª ×”×§×©×¨
        context = "\n\n".join([
            f"Document {i+1}:\n{doc}"
            for i, doc in enumerate(self.documents)
        ])
        
        prompt = f"""
        Answer the question based ONLY on the provided documents.
        If the answer is not in the documents, say "I don't know".
        
        Documents:
        {context}
        
        Question: {question}
        """
        
        response = self.model.generate_content(prompt)
        return response.text

# ×©×™××•×©
docs = [
    "Our company was founded in 2010 in San Francisco.",
    "We have 500 employees across 10 countries.",
    "Our main product is an AI platform for businesses."
]

rag = RAGSystem(docs)
answer = rag.query("When was the company founded?")
print(answer)  # "2010"
```

×˜×™×¤×™× ××ª×§×“××™×
==============

1. Generation Config
--------------------

```python
config = {
    "temperature": 0.7,  # 0-2, ×’×‘×•×”=×™×¦×™×¨×ª×™
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 2048,
    "response_mime_type": "application/json"
}

model = genai.GenerativeModel(
    'gemini-1.5-flash',
    generation_config=config
)
```

2. Safety Settings
------------------

```python
safety_settings = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
    }
]

model = genai.GenerativeModel(
    'gemini-1.5-flash',
    safety_settings=safety_settings
)
```

3. Error Handling
-----------------

```python
from google.api_core import exceptions

try:
    response = model.generate_content(prompt)
    return response.text
except exceptions.ResourceExhausted:
    print("Quota exceeded")
except exceptions.InvalidArgument:
    print("Invalid input")
except Exception as e:
    print(f"Error: {e}")
```

4. Caching
----------

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_generate(prompt):
    response = model.generate_content(prompt)
    return response.text
```

5. Streaming
------------

```python
def stream_response(prompt):
    response = model.generate_content(
        prompt,
        stream=True
    )
    
    for chunk in response:
        print(chunk.text, end='', flush=True)
```

Best Practices
==============

1. API Key
----------
âœ“ ×”×©×ª××© ×‘-.env
âœ“ ××œ ×ª×©×ª×£ ×‘×§×•×“
âœ“ ×¨×•×˜×¦×™×” ×ª×§×•×¤×ª×™×ª

2. Prompts
----------
âœ“ ×‘×¨×•×¨×™× ×•×¡×¤×¦×™×¤×™×™×
âœ“ ×“×•×’×××•×ª ×›×©××¤×©×¨
âœ“ ×”×§×©×¨ ××œ×

3. Performance
--------------
âœ“ Flash ×œ×¤×©×•×˜
âœ“ Pro ×œ××•×¨×›×‘
âœ“ Batch requests

4. Cost
-------
âœ“ × ×˜×¨ ×©×™××•×©
âœ“ Cache ×ª×•×¦××•×ª
âœ“ ×‘×—×¨ ××•×“×œ × ×›×•×Ÿ

5. Testing
----------
âœ“ ×‘×“×•×§ Edge cases
âœ“ Test ×‘×™×™×¦×•×¨
âœ“ Monitor errors

×¡×™×›×•×
=====

âœ“ 10 ××ª×›×•× ×™× ××•×›× ×™×
âœ“ ×§×•×“ ××œ× ×•×¢×•×‘×“
âœ“ ×“×•×’×××•×ª ××¢×©×™×•×ª
âœ“ Tips & Best Practices
âœ“ Production-ready

×”×ª×—×œ ×œ×‘×©×œ! ğŸ‘¨â€ğŸ³

---
Â© 2026 Google AI Academy
AI Studio Cookbook
×’×¨×¡×” 5.0
